- 在深度学习里我们把收集到的真实数据叫做样本，样本里的输入叫做特征（ feature），样本里希望模型预测的值叫做标签（ label）。深度学习的模型就是一个函数，这个函数的输入是样本的 feature，输出是预测值。训练过程就是调节函数内部的参数（ Parameter）（也可以叫做权重（ weight）），来让预测值尽可能的接近 label。当模型训练好之后，就可以只输入新的样本的 feature，模型根据学习到的内部参数，计算出预测值了。

- 样本点的 feature 用 x 来表示， label 我们用 y 来表示，通过直线预测的销量用 $\hat{y}$ 来表示。$x ^ {i}$ 表示第 i 个样本点的 feature，$y ^ {i}$ 表示第 i 个样本点的 label。$\hat{y} ^ {i}$ 表示第 i 个预测的销量值。则针对我们收集的这 7 个样本的误差平方和就可以表示为：
$$
\text { loss }=\sum_{i=1} ^ {m}\left(y ^ {i}-\hat{y} ^ {i}\right) ^ {2}
$$

- 在深度学习里，我们把上式叫做损失函数，损失函数就是衡量预测值和真实值（ label）之间的差距的。模型训练的目的就是降低 loss。 拟合直线里有一个可以训练的参数 w，预测值 $\hat{y} ^ {i}$ 可以表示为 :
$$
\hat{y} ^ {i}=w \times x ^ {i}
$$

- 带入 $\hat{y} ^ {i}$ 则有：
$$
loss= \sum_{i=1} ^ {7} \left( y ^ {i}-w \times x ^ {i} \right) ^ {2}
$$

- 根据之前我们学过导数的性质，如果一个函数存在极值，那么它的导数为 0 。我们让 loss 函数对 w 求导，并让导数等于 0 。从而求解出 w。

在机器学习里的算法分为监督学习算法，无监督学习算法，强化学习算法。
##### 监督学习：
在监督学习中，数据集中每个样本都有输入特征（ X）和对应的标签（ Y）。算法通过学习数据中的输入 - 标签关系来进行预测。机器学习中大部分的算法都是监督学习，比如我们刚才讲的线性回归。还有比如你要让模型通过宠物照片识别照片中是猫还是狗，你提供给模型的训练数据里，必须包含人标注的数据。也就是通过 label 告诉模型每个训练照片是猫还是狗，让模型学习特征和标签之间的关系。
##### 无监督学习：
在无监督学习中，数据集中只有输入特征（ X），没有标签（ Y）。算法自动发现数据中的模式对数据进行分析。无监督学习最常见的模型就是聚类模型，比如电信运营商根据所有用户的消费数据，让模型自动发现用户的消费习惯，有的是电话多，有的是流量多，从而聚类出很多套餐类别。在这里并不需要标注数据，只有输入特征，让算法自己去寻找数据里的规律。
##### 强化学习：
在强化学习里，无法直接给出输入特征（ X）对应的标签（ Y），而只能给出特征对应的奖励值（ R）。模型在训练过程中，不断优化参数，追求更高的奖励。比如你用强化学习训练一个下围棋的模型，针对每一步你无法给出下一步棋下在哪里最好，但是却可以通过棋局最终的输赢的子数来给模型每一步设定奖励值。

在监督学习里，又主要分为回归和分类两种算法。
##### 回归：
当你要预测的变量是连续型变量，那么这个算法就是回归算法。比如预测一个人的身高，体重，收入等。
##### 分类 :
当你要预测的变量是可数的离散型变量，那么这个算法就是分类算法，比如预测一张宠物图片是猫还是狗。

分类很好理解，就是根据特征对实例进行分类。那预测连续型变量为什么叫做回归呢？